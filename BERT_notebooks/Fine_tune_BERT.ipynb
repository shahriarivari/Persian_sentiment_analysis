{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPAIDwoN+9KjH355uawCQNi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahriarivari/Persian_sentiment_analysis/blob/main/BERT_notebooks/Fine_tune_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##pip installs"
      ],
      "metadata": {
        "id": "0RE70MtNwwwv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YFrQ_TNqwGQQ",
        "outputId": "e541500c-e5b7-4a82-9601-797a13cc4488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.11.17)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.25.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed transformers-4.36.2\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.9.4-py3-none-any.whl (371 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.7/371.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasttext-wheel<0.10.0,>=0.9.2 (from hazm)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flashtext<3.0,>=2.7 (from hazm)\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (4.3.2)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (3.8.1)\n",
            "Collecting numpy==1.24.3 (from hazm)\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-crfsuite<0.10.0,>=0.9.9 (from hazm)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.2.2)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel<0.10.0,>=0.9.2->hazm)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (67.7.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.66.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.2.0)\n",
            "Building wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9296 sha256=899bed47963a007cc7c5ff8160c1690fd8217996f080ddfeb7eb1ea995f99150\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/be/39/c37ad168eb2ff644c9685f52554440372129450f0b8ed203dd\n",
            "Successfully built flashtext\n",
            "Installing collected packages: python-crfsuite, flashtext, pybind11, numpy, fasttext-wheel, hazm\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fasttext-wheel-0.9.2 flashtext-2.7 hazm-0.9.4 numpy-1.24.3 pybind11-2.11.1 python-crfsuite-0.9.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stopwords_guilannlp\n",
            "  Downloading stopwords_guilannlp-13.2019.3.5-py3-none-any.whl (8.2 kB)\n",
            "Installing collected packages: stopwords_guilannlp\n",
            "Successfully installed stopwords_guilannlp-13.2019.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install tokenizers\n",
        "!pip install datasets\n",
        "!pip install -U accelerate\n",
        "!pip install -U transformers\n",
        "!pip install hazm\n",
        "!pip install stopwords_guilannlp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##import libraries"
      ],
      "metadata": {
        "id": "R68TDDOAw4k3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader , Dataset\n",
        "\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import BertModel, BertConfig\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import codecs\n",
        "\n",
        "# Preprocessing\n",
        "from stopwords_guilannlp import stopwords_output\n",
        "from hazm import *\n",
        "\n",
        "# Visualization\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import plot_model\n",
        "# Measuring metrics\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "-XFlnDTsw6do"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "id": "TgkUCTLN02Ge",
        "outputId": "c785409c-4568-46e7-ebac-6e40bfdbb881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import and analyze SA Dataset"
      ],
      "metadata": {
        "id": "iKDgMWmIzQuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('test.csv', index_col=None, header=None, encoding=\"utf-8\")"
      ],
      "metadata": {
        "id": "iGT4IvF9zR1W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test[0]\n",
        "y_test = test[1]\n",
        "print('Number of testing sentence: ', x_test.shape)\n",
        "print('Number of testing label: ', y_test.shape)"
      ],
      "metadata": {
        "id": "esJy9vFBw32t",
        "outputId": "3e92a9aa-afac-46aa-8f00-bebdad5e5694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of testing sentence:  (1854,)\n",
            "Number of testing label:  (1854,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a binarray dataset since the dataset has mutiple labels\n",
        "\n",
        "binary_y_test = []\n",
        "binary_x_test = []\n",
        "for i, y in enumerate(y_test):\n",
        "  if int(y) != 0:\n",
        "    if int(y) > 0:\n",
        "      binary_y_test.append(1)\n",
        "      binary_x_test.append(x_test[i])\n",
        "    else:\n",
        "      binary_y_test.append(0)\n",
        "      binary_x_test.append(x_test[i])\n",
        "\n",
        "# convert them into np arrays\n",
        "x_test = np.asarray(binary_x_test)\n",
        "y_test = np.asarray(binary_y_test)"
      ],
      "metadata": {
        "id": "7McLEhXwzTkB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import other datasets for sentiment analysis"
      ],
      "metadata": {
        "id": "KuIOdlDbzUnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing othere datasets\n",
        "original = pd.read_csv('original.csv', index_col=None, header=None, encoding=\"utf-8\")\n",
        "balanced = pd.read_csv('balanced.csv', index_col=None, header=None, encoding=\"utf-8\")\n",
        "translation = pd.read_csv('translation.csv', index_col=None, header=None, encoding=\"utf-8\")"
      ],
      "metadata": {
        "id": "O0RntiFwzZD3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we select a dataset to work with\n",
        "# selected_dataset = original\n",
        "# using all of the dataset\n",
        "stacked_df = pd.concat([original, balanced, translation], ignore_index=True)\n",
        "# shuffle the dataframe\n",
        "selected_dataset = stacked_df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "cCwey1y6zaOq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating train data\n",
        "x_train = selected_dataset[0]\n",
        "y_train = selected_dataset[1]\n",
        "print('Number of training sentence: ', x_train.shape)\n",
        "print('Number of training label: ', y_train.shape)"
      ],
      "metadata": {
        "id": "jPz2g_W8zbQJ",
        "outputId": "fe4990af-0653-4d2f-a640-709de25fcf06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentence:  (26630,)\n",
            "Number of training label:  (26630,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# again make our dataset binarray\n",
        "binary_y_train = []\n",
        "binary_x_train = []\n",
        "for i, y in enumerate(y_train):\n",
        "  if int(y) != 0:\n",
        "    if int(y) > 0:\n",
        "      binary_y_train.append(1)\n",
        "      binary_x_train.append(x_train[i])\n",
        "    else:\n",
        "      binary_y_train.append(0)\n",
        "      binary_x_train.append(x_train[i])\n",
        "\n",
        "# Convert dataframes to numpy arrays\n",
        "x_train = np.asarray(binary_x_train)\n",
        "y_train = np.asarray(binary_y_train)"
      ],
      "metadata": {
        "id": "6Tdzb05fzcWp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Plot some information about our downstream task dataset"
      ],
      "metadata": {
        "id": "UfsMTh0uzenj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# See the data number of sentence in each category\n",
        "cnt = Counter(y_train)\n",
        "cnt = dict(cnt)\n",
        "print(cnt)\n",
        "\n",
        "labels = list(cnt.keys())\n",
        "sizes = list(cnt.values())\n",
        "colors = ['#3fba36', '#66b3ff','#ffcc99','#ff9999', '#d44444']\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, labels=labels, colors=colors,\n",
        "        autopct='%1.1f%%', startangle=90)\n",
        "#draw circle\n",
        "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
        "fig = plt.gcf()\n",
        "fig.gca().add_artist(centre_circle)\n",
        "# Equal aspect ratio ensures that pie is drawn as a circle\n",
        "ax1.axis('equal')\n",
        "plt.tight_layout()\n",
        "# Decomment following line if you want to save the figure\n",
        "# plt.savefig('distribution.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "00wM6XIIze70",
        "outputId": "80db44e3-c39d-4cca-d22a-dfdc0be5ad86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 14395, 0: 3826}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing"
      ],
      "metadata": {
        "id": "pj_A9TFOzhGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "puncs = ['،', '.', ',', ':', ';', '\"']\n",
        "normalizer = Normalizer()\n",
        "lemmatizer = Lemmatizer()\n",
        "\n",
        "# turn a doc into clean tokens\n",
        "def clean_doc(doc):\n",
        "    doc = normalizer.normalize(doc) # Normalize document using Hazm Normalizer\n",
        "    tokenized = word_tokenize(doc)  # Tokenize text\n",
        "    tokens = []\n",
        "    for t in tokenized:\n",
        "      temp = t\n",
        "      for p in puncs:\n",
        "        temp = temp.replace(p, '')\n",
        "      tokens.append(temp)\n",
        "    # tokens = [w for w in tokens if not w in stop_set]    # Remove stop words\n",
        "    tokens = [w for w in tokens if not len(w) <= 1]\n",
        "    tokens = [w for w in tokens if not w.isdigit()]\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in tokens] # Lemmatize sentence words using Hazm Lemmatizer\n",
        "    tokens = ' '.join(tokens)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "y0jft9Myzi5v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing step to training data\n",
        "train_docs = np.empty_like(x_train)\n",
        "for index, document in enumerate(x_train):\n",
        "  train_docs[index] = clean_doc(document)\n",
        "\n",
        "# Applying preprocessing step to test data\n",
        "test_docs = np.empty_like(x_test)\n",
        "for index, document in enumerate(x_test):\n",
        "  test_docs[index] = clean_doc(document)"
      ],
      "metadata": {
        "id": "w0m-kkeOzkF9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load the pretrained model and tokenizer"
      ],
      "metadata": {
        "id": "RDJnHBAC0YRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount to google drive\n",
        "import zipfile\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "zip_file_path = '/content/drive/MyDrive/bert_pretrained_model.zip'\n",
        "# Create a directory to extract the contents\n",
        "extract_path = '/content/bert_pretrained_model/'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "lZJAGtRE0a6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount to google drive\n",
        "import zipfile\n",
        "\n",
        "# Create a directory to extract the contents\n",
        "extract_path = '/content/bert_pretrained_model/'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "# Extract the contents of the zip file\n",
        "zip_file_path = '/content/bert_pretrained_model.zip'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "nB5tuyhryt89"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved BERT model\n",
        "bert_model = BertModel.from_pretrained(os.path.join(\"bert_pretrained_model\", \"final_model\"))"
      ],
      "metadata": {
        "id": "C_X1XW9q0o1X",
        "outputId": "45d5e3d6-a8fa-4f65-c72a-8056ba942e16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at bert_pretrained_model/final_model and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_output_dir = \"bert_tokenizer\"\n",
        "os.mkdir(tokenizer_output_dir)"
      ],
      "metadata": {
        "id": "gJYwvblH0tLS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(tokenizer_output_dir, max_len = 256)"
      ],
      "metadata": {
        "id": "AUfp3CEn0ur0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##classifiers"
      ],
      "metadata": {
        "id": "Q-tWF6Eh07dJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###MLP"
      ],
      "metadata": {
        "id": "eu1GfjAf1DJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your MLP classifier\n",
        "class MLPClassifier(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Linear(input_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        # nn.Linear(hidden_size, 32),\n",
        "        # nn.ReLU(),\n",
        "        nn.Linear(hidden_size, output_size),\n",
        "        #nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.mlp(x)"
      ],
      "metadata": {
        "id": "cO7fhJHT09me"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##tokenizing data"
      ],
      "metadata": {
        "id": "OUn4PADZ2qpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize train_docs and test_docs using the trained tokenizer\n",
        "train_tokenized = tokenizer(train_docs.tolist(),max_length=256, truncation=True, padding=True,\n",
        "                            return_tensors='pt')\n",
        "\n",
        "test_tokenized = tokenizer(test_docs.tolist(),max_length=256, truncation=True, padding=True,\n",
        "                           return_tensors='pt')"
      ],
      "metadata": {
        "id": "AXKWfff52u54"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###create a dataset object"
      ],
      "metadata": {
        "id": "etXn5PYH2yws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, inputs, labels):\n",
        "        self.inputs = inputs\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.inputs[\"input_ids\"][idx],\n",
        "            \"attention_mask\": self.inputs[\"attention_mask\"][idx],\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        }"
      ],
      "metadata": {
        "id": "OoJ39kXu29H4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create datalaoders"
      ],
      "metadata": {
        "id": "L5DBKN-f3ByW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "# Create DataLoader\n",
        "train_dataset = CustomDataset(train_tokenized, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Create DataLoader\n",
        "test_dataset = CustomDataset(test_tokenized, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "w7N7-SId3EYL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Initialize MLP Classifier and Define Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "_VOnOuAh31uI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize MLP classifier\n",
        "input_size = bert_model.config.hidden_size  # Get the size of the pooled representation\n",
        "hidden_units = 128  # Adjust as needed\n",
        "output_size = 1  # Binary classification, 1 output unit\n",
        "learning_rate = 0.01\n",
        "torch.manual_seed(42)\n",
        "classifier = MLPClassifier(input_size=input_size, hidden_size=hidden_units, output_size=output_size)\n",
        "\n",
        "# remove the pooler layer in bert\n",
        "bert_model.pooler = None\n",
        "\n",
        "# Move your model and data loaders to the selected device\n",
        "bert_model.to(device)\n",
        "classifier.to(device)\n",
        "\n",
        "# Freeze all BERT layers\n",
        "for param in bert_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# BCE loss\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "# Specify the parameters to be optimized\n",
        "optimizer = torch.optim.AdamW([{'params': classifier.parameters(), 'lr': learning_rate}])"
      ],
      "metadata": {
        "id": "8kcwC7MV32ay"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training loop\n"
      ],
      "metadata": {
        "id": "mbn8DN-S4CdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accumulation_steps = 5  # Accumulate gradients over 8 batches\n",
        "bert_output = []\n",
        "classifier_output = []\n",
        "input = []\n",
        "\n",
        "bert_model.eval()\n",
        "\n",
        "for epoch in range(5):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    test_loss = 0.0\n",
        "    print(\"epoch = \", epoch + 1)\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "    # Training\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        inputs = batch[\"input_ids\"].to(device)\n",
        "        input.append(inputs)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        classifier.train()\n",
        "\n",
        "        bert_outputs = bert_model(input_ids=inputs, attention_mask=attention_mask)\n",
        "        bert_output.append(bert_outputs)\n",
        "        bert_last_hidden_states = bert_outputs.last_hidden_state\n",
        "\n",
        "        classifier_outputs = classifier(bert_last_hidden_states[:, 0, :])\n",
        "        classifier_output.append(classifier_outputs)\n",
        "        loss = criterion(classifier_outputs, labels.unsqueeze(dim=1))\n",
        "        loss = loss / accumulation_steps  # Normalize the loss if using gradient accumulation\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters every accumulation_steps batches\n",
        "        if (batch_idx + 1) % accumulation_steps == 0 or batch_idx == len(train_loader) - 1:\n",
        "            optimizer.zero_grad()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Calculate average loss per batch for training\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "    print(f\"train loss per batch = {train_loss}\")\n",
        "\n",
        "    # Validation\n",
        "    classifier.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for batch_idx, batch in enumerate(test_loader):\n",
        "            inputs = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            bert_outputs = bert_model(input_ids=inputs, attention_mask=attention_mask)\n",
        "            bert_last_hidden_states = bert_outputs.last_hidden_state\n",
        "            classifier_outputs = classifier(bert_last_hidden_states[:, 0, :])\n",
        "            loss = criterion(classifier_outputs, labels.unsqueeze(dim=1))\n",
        "            test_loss += loss.item()\n",
        "\n",
        "        # Calculate average loss per batch for testing\n",
        "        test_loss = test_loss / len(test_loader)\n",
        "        print(f\"test loss per batch = {test_loss}\")\n"
      ],
      "metadata": {
        "id": "LW3-k7Dp4GoK",
        "outputId": "1da4c73d-7220-4144-c991-11263375c0f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch =  1\n",
            "---------------------------------------\n",
            "train loss per batch = 0.14189088339345496\n",
            "test loss per batch = 0.7113478547996945\n",
            "epoch =  2\n",
            "---------------------------------------\n",
            "train loss per batch = 0.14189088339345496\n",
            "test loss per batch = 0.7113478547996945\n",
            "epoch =  3\n",
            "---------------------------------------\n",
            "train loss per batch = 0.14189088339345496\n",
            "test loss per batch = 0.7113478547996945\n",
            "epoch =  4\n",
            "---------------------------------------\n",
            "train loss per batch = 0.14189088339345496\n",
            "test loss per batch = 0.7113478547996945\n",
            "epoch =  5\n",
            "---------------------------------------\n",
            "train loss per batch = 0.14189088339345496\n",
            "test loss per batch = 0.7113478547996945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_output[9].last_hidden_state.mean(), bert_output[9].last_hidden_state.std()"
      ],
      "metadata": {
        "id": "FW5fWGpg2Piz",
        "outputId": "a5a8fa93-c037-446e-e3f8-fac95c3685f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0006, device='cuda:0'), tensor(1.0030, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_output[0].last_hidden_state.mean() , bert_output[0].last_hidden_state[:,0,:].shape"
      ],
      "metadata": {
        "id": "vUQYsQj5131p",
        "outputId": "34eb10b5-b288-447c-a4e9-31902130f790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0006, device='cuda:0'), torch.Size([64, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}